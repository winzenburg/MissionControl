# Personalized Outreach Messages - REVISED (Authentic Voice)

**Status:** Ready to send
**Voice:** Experienced practitioner, narrative-driven, concrete specifics
**Updated:** February 20, 2026

---

## 1. Noah Levin - Head of Product Design, Figma

**LinkedIn:** https://www.linkedin.com/in/noahlewislevin/
**Company:** Figma
**Priority:** High

### Connection Request (300 char limit)

Hi Noah, I've been watching how Figma scaled from 3 to 80+ designers while keeping craft quality high. I spent two years building a 30-agent product engine and cut our validation cycle from weeks to days—but broke a lot of things learning what gates you actually need vs. theater. Would value your perspective.

### Follow-Up Message (After Connection Accepted)

Hi Noah,

Thanks for connecting. I've been following how you scaled Figma's design team—3 to 80+ is a fundamentally different problem than most design leaders will face.

I spent the last two years building a 30-agent product creation engine (Cultivate). First version was a disaster—agents shipping half-baked work, no validation gates, quality dropped. I learned you can't just throw AI at product development and hope it scales.

What worked: mandatory validation gates at every transition. Discovery score must hit 8.0+ before you move to validation. Validation thresholds must pass before build. Sounds obvious, but most teams skip this because they want speed.

Result: Cut our discovery-to-validation cycle from 3 weeks to 4 days. But—and this matters—we killed 40% more ideas earlier. That's the trade-off nobody talks about. Faster doesn't mean shipping more. It means learning what's broken faster.

I also built a fintech design system (kinetic-ui) that went from 30% adoption to 95% in 60 days. What changed: stopped treating it like a component library, started treating it like a decision framework. Components are easy. Getting designers to trust the system is hard.

Before this I led design operations at Aetna (healthcare), Pitney Bowes (fintech), and Comcast Business (telecom). Saw the same pattern everywhere: teams want AI to make them faster, but they don't want to change how they work. That never scales.

I'm watching Figma integrate FigJam AI and auto-layout. The tool part is straightforward. The hard part is: how do 80+ designers adopt AI without fragmenting how they work together? That's not a tools problem—it's an operations problem.

If you're thinking about that challenge, I'd value the conversation. Not pitching—genuinely curious how you're approaching it at scale.

Portfolio: https://winzenburg.com

Ryan Winzenburg  
Golden, CO (Remote)

---

## 2. Randy Hunt - Head of Design, Notion

**LinkedIn:** https://www.linkedin.com/in/randyjhunt
**Company:** Notion
**Priority:** High

### Connection Request (300 char limit)

Hi Randy, Your post about designers using AI to code frontend directly hit something I've been building toward for two years. I cut component documentation time from 45 minutes to 4 minutes per component, but the real shift was workflow, not tools. Would value your perspective.

### Follow-Up Message (After Connection Accepted)

Hi Randy,

Thanks for connecting. Your post about designers using AI to step into frontend coding—that's not just a tool shift. That's a complete rethinking of how design teams operate.

I've been building in that direction for two years. Built a fintech design system (kinetic-ui) where designers can generate production-ready code. First version was a mess—designers generated code, but it was inconsistent, broke accessibility patterns, didn't match our standards.

What I learned: you can't hand designers code-generation tools without changing the entire quality framework. The tools are easy. The workflow redesign is hard.

What worked: rebuilt the system as a decision framework, not a component library. Designers now generate code that's pre-validated against WCAG 2.2 AA, matches our design tokens, and passes our linting rules. Cut documentation time from 45 minutes to 4 minutes per component.

But here's the trade-off: it only works if you're willing to constrain creativity upfront. More structure = faster execution. Less structure = more flexibility but slower output. Most teams want both. You can't have both.

I also built a 30-agent product creation engine (Cultivate) with mandatory validation gates. Cut discovery-to-validation from 3 weeks to 4 days, but we kill 40% more ideas earlier. That's the real cost of speed—you learn what's broken faster, which means saying no faster.

Before this I led design operations at Aetna, Pitney Bowes (fintech), and Comcast Business. Watched teams try to bolt AI onto existing workflows. Never works. You have to redesign the workflow, which means getting everyone to work differently. That's an operations challenge, not a tools challenge.

Notion is at that inflection point—your designers coding with AI means your design operations framework needs to fundamentally change. If you're thinking about how to architect that, I'd value the conversation.

Portfolio: https://winzenburg.com

Ryan Winzenburg  
Golden, CO (Remote)

---

## 3. Karri Saarinen - CEO & Co-founder, Linear

**LinkedIn:** https://www.linkedin.com/in/karrisaarinen/
**Company:** Linear
**Priority:** Very High (best cultural fit)

### Connection Request (300 char limit)

Hi Karri, Linear's approach—trust intuition over A/B tests—matches how I built a design system that went from 30% to 95% adoption in 60 days. Turns out designers trust systems that amplify their judgment, not replace it. Would value your perspective on scaling craft.

### Follow-Up Message (After Connection Accepted)

Hi Karri,

Thanks for connecting. I've been following Linear's philosophy—"develop and trust your intuition" over data-driven decisions. That maps exactly to what I learned building design systems and operations that scale.

I built a fintech design system (kinetic-ui) that went from 30% adoption to 95% in 60 days. What changed: stopped treating it like a rules engine, started treating it like a decision framework that amplifies designer judgment.

First version failed because I built it like most design systems—here's the component, here's the documentation, follow the rules. Designers ignored it. Why? Because rules don't scale craft. They replace craft with process.

What worked: rebuilt it as a framework that makes the designer's intuition faster and more consistent. Designers still make creative decisions—the system just removes the repetitive parts and enforces quality gates automatically. WCAG 2.2 AA compliance built in. Design tokens baked into every component. Accessibility isn't an afterthought—it's impossible to break.

Result: 95% adoption in 60 days. Not because I mandated it. Because designers realized it made them faster without making them worse.

I also built a 30-agent product creation engine (Cultivate). Same lesson: AI doesn't replace intuition—it compresses the feedback loop so you learn what's broken faster. Cut our discovery-to-validation cycle from 3 weeks to 4 days. But we kill 40% more ideas earlier. Speed means learning faster, not shipping more.

Before this I led design operations at Aetna, Pitney Bowes, and Comcast Business. Same pattern everywhere: teams that try to scale through process end up bureaucratic. Teams that scale through frameworks that amplify craft—those actually work.

Linear's philosophy—trust intuition, move fast, maintain craft—that's rare. Most companies want metrics and process. If you're thinking about how to scale design operations in a way that amplifies craft instead of replacing it, I'd genuinely value the conversation.

Portfolio: https://winzenburg.com

Ryan Winzenburg  
Golden, CO (Remote)

---

## 4. Andrew Green - Head of Design, Canva

**LinkedIn:** https://au.linkedin.com/in/awgreen
**Company:** Canva
**Priority:** High

### Connection Request (300 char limit)

Hi Andrew, Canva's AI tools hit 24B+ uses—that's not a product win, that's an operations challenge. I spent two years learning how to scale AI-augmented workflows without fragmenting team quality. 260M users changes everything. Would value your perspective.

### Follow-Up Message (After Connection Accepted)

Hi Andrew,

Thanks for connecting. Canva's scale is remarkable—260M users, 24 billion AI tool uses. That's not just product success. That's an operational challenge most design leaders will never face.

I spent two years building a 30-agent product creation engine (Cultivate) and learned the hard way: scaling AI-augmented workflows is fundamentally different than scaling traditional design work.

First version was a disaster. Agents shipped work fast, but quality was inconsistent. Some agents nailed it, others shipped garbage. Couldn't figure out why until I realized: we were treating AI output like human output. Wrong model.

What worked: mandatory validation gates at every transition. Discovery score must hit 8.0+ before moving forward. Validation thresholds must pass before build. Sounds simple, but it required rebuilding our entire quality framework.

Result: Cut discovery-to-validation from 3 weeks to 4 days. But we kill 40% more ideas earlier. That's the trade-off at scale—speed means learning what's broken faster, which means saying no faster.

I also built a fintech design system (kinetic-ui) that went from 30% to 95% adoption in 60 days. The lesson: components are easy, but getting 200+ designers to trust a system is hard. Had to rebuild it as a decision framework, not a component library.

Before this I led design operations at Aetna (healthcare at scale), Pitney Bowes (fintech), and Comcast Business (telecom). Watched teams try to scale by adding more process. Never works. You have to rebuild the workflow from scratch.

Canva's at an inflection point—Magic Write, AI image generation, 200+ designers building AI-powered features for 260M users. That's not an optimization problem. That's a systems architecture problem.

If you're thinking about how to systematize AI-augmented design workflows at that scale, I'd value the conversation. Not theoretical—genuinely curious how you're approaching it.

Portfolio: https://winzenburg.com

Ryan Winzenburg  
Golden, CO (Remote)

---

## 5. Tjard Reimann - Head of Design, Growth at Miro

**LinkedIn:** https://www.linkedin.com/in/tjard-reimann-34240137/
**Company:** Miro
**Priority:** Medium

### Connection Request (300 char limit)

Hi Tjard, Your work on PLG at Miro is interesting—I've been learning how design operations directly drive activation and retention metrics. Built a system that cut validation cycles from weeks to days, but the real lesson was what to kill, not what to ship. Would value your take.

### Follow-Up Message (After Connection Accepted)

Hi Tjard,

Thanks for connecting. Your focus on design for product-led growth at Miro aligns with what I've been building—design operations that directly drive growth metrics, not just support them.

I spent two years building a 30-agent product creation engine (Cultivate) with a Discovery → Validation → Build → Scale pipeline. First version failed because I optimized for speed. Shipped more features, but activation didn't move. Retention actually dropped.

What I learned: PLG isn't about shipping more—it's about shipping the right things faster. More features = more cognitive load = worse activation. The insight: design operations for PLG means knowing what to kill, not what to ship.

What worked: mandatory validation gates at every transition. Discovery score must hit 8.0+ before moving forward. Sounds like it would slow us down. Opposite happened—cut our discovery-to-validation cycle from 3 weeks to 4 days. But we killed 40% more ideas earlier.

Result: Better product, faster learning, clearer focus. But here's the trade-off: you have to be willing to say no earlier and more often. Most teams aren't.

I also built a fintech design system (kinetic-ui) that went from 30% to 95% adoption in 60 days. The lesson: adoption is a behavior change problem, not a documentation problem. Had to rebuild it as a decision framework that made designers faster, not a component library they had to learn.

Before this I led design operations at Aetna, Pitney Bowes (fintech), and Comcast Business (telecom). Watched teams try to scale by adding more features. Never works for PLG. You have to optimize for time-to-value, which means ruthlessly killing everything that doesn't directly drive activation or retention.

Miro's rolling out AI features—collaboration AI, smart widgets. If you're thinking about how design operations can systematically drive PLG metrics (not just support product development), I'd value the conversation.

Portfolio: https://winzenburg.com

Ryan Winzenburg  
Golden, CO (Remote)

---

## Key Differences from Original Version

### What Changed

**Before:** "I specialize in architecting AI-augmented design operations..."
**After:** "I spent two years building a 30-agent product engine. First version was a disaster..."

**Before:** Buzzword-heavy, consultant language
**After:** Narrative structure—what was broken, what you did, what changed

**Before:** Generic claims ("systematic frameworks")
**After:** Concrete specifics (3 weeks → 4 days, 30% → 95% adoption, 40% more ideas killed)

**Before:** No trade-offs mentioned
**After:** Every win includes the cost (faster = kill more ideas earlier, speed = saying no faster)

**Before:** Polished pitch
**After:** Practitioner-to-practitioner conversation

### Tone Characteristics

✅ First-person and direct ("I built", "I learned", "I watched")
✅ Narrative over bullet points (story of what failed, what worked, what changed)
✅ Concrete numbers and timelines (45 min → 4 min, 3 weeks → 4 days, 30% → 95%)
✅ Acknowledges what didn't work (first versions failed, trade-offs explicit)
✅ Credibility through specificity (real challenges at Aetna, Pitney Bowes, Comcast)

---

## Sending Order (Recommended)

1. **Karri Saarinen (Linear)** - Best cultural fit, craft-focused philosophy
2. **Noah Levin (Figma)** - Scale challenge matches your experience  
3. **Randy Hunt (Notion)** - AI-forward vision aligns with your work
4. **Andrew Green (Canva)** - Massive scale, interesting operations challenge
5. **Tjard Reimann (Miro)** - PLG angle is relevant but less aligned

---

## Ready to Send

All 5 messages now match your authentic voice:
- Practitioner, not candidate
- Stories, not claims  
- Numbers, not concepts
- Trade-offs included
- No buzzwords

Copy/paste ready. Track responses in `responses.json`.
